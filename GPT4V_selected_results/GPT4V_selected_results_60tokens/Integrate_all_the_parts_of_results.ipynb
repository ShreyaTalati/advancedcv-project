{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMS1C+CGcZKxoHdPzqusrZe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install github-clone\n",
        "!ghclone https://github.com/ShreyaTalati/advancedcv-project/tree/main/GPT4V_selected_results/GPT4V_selected_results_60tokens/raw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuBsnjCHX2e8",
        "outputId": "88531cc4-e260-4266-a954-acb32889038b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting github-clone\n",
            "  Downloading github_clone-1.2.0-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from github-clone) (2.31.0)\n",
            "Collecting docopt>=0.6.2 (from github-clone)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->github-clone) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->github-clone) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->github-clone) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->github-clone) (2023.7.22)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=d5fb484b0ce4513ad04ae97feb96b70b443b36f3bd77f52b289011d83ce84d58\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt, github-clone\n",
            "Successfully installed docopt-0.6.2 github-clone-1.2.0\n",
            "Cloning into 'raw'...\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jajEumveXCZs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "predictions = []\n",
        "for i in range(1, 8):\n",
        "  pred = np.load(\"raw/GPT4V_selected_results_part\" + str(i) + \".npy\").tolist()\n",
        "  for p in pred:\n",
        "    predictions.append(p)\n",
        "np.save(\"GPT4V_selected_results_test_60tokens.npy\", predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# Helper function to clean captions\n",
        "def handle_caption(caption):\n",
        "  punctuation = set(string.punctuation)\n",
        "\n",
        "  if caption.endswith('\\n'):\n",
        "    caption = caption[:-len('\\n')]\n",
        "  if caption.endswith('�'):\n",
        "    caption = caption[:-len('�')]\n",
        "\n",
        "  # lower case\n",
        "  caption = caption.lower()\n",
        "\n",
        "  # remove underlines\n",
        "  caption = caption.replace(\"_\", \" \")\n",
        "\n",
        "  # remove punctuations\n",
        "  caption = ''.join([c for c in caption if not c in punctuation])\n",
        "\n",
        "  # remove extra spaces\n",
        "  caption = ' '.join(caption.split())\n",
        "\n",
        "  return caption"
      ],
      "metadata": {
        "id": "kv9EPL-HPEOk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(predictions)):\n",
        "  predictions[i] = handle_caption(predictions[i])\n",
        "np.save(\"GPT4V_selected_results_test_60tokens_cleaned.npy\", predictions)"
      ],
      "metadata": {
        "id": "T4OewgThPE6m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjDcJ5IOXe7J",
        "outputId": "244e49d8-ed04-4f8f-c101-2420f85dab42"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}